{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7709799,"sourceType":"datasetVersion","datasetId":4501675},{"sourceId":7710127,"sourceType":"datasetVersion","datasetId":4501930}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nibakh/hate-speech-part-1-model-comparisons?scriptVersionId=170139338\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, LSTM, Dense\n\n# Load data\ndata = pd.read_csv('/kaggle/input/datset15/labeled_data.csv')  # Replace 'your_data.csv' with your dataset path\nX = data['tweet']\ny = data['class']\n\n# data = pd.read_csv('/kaggle/input/dataset101/HateSpeechDataset.csv')  # Replace 'your_data.csv' with your dataset path\n# X = data['Content']\n# y = data['Label']\n\n\n#three labels # hatespeech,ofensive,neither\n# trial with other dataset with 2 labels 1 for offensive and 0 for non offensive","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-03T17:59:20.835111Z","iopub.execute_input":"2024-04-03T17:59:20.835492Z","iopub.status.idle":"2024-04-03T17:59:20.902159Z","shell.execute_reply.started":"2024-04-03T17:59:20.835461Z","shell.execute_reply":"2024-04-03T17:59:20.901147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(data)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T12:46:19.79333Z","iopub.execute_input":"2024-03-17T12:46:19.794169Z","iopub.status.idle":"2024-03-17T12:46:19.800477Z","shell.execute_reply.started":"2024-03-17T12:46:19.794133Z","shell.execute_reply":"2024-03-17T12:46:19.799469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-03-27T11:52:11.100927Z","iopub.execute_input":"2024-03-27T11:52:11.102027Z","iopub.status.idle":"2024-03-27T11:52:11.118356Z","shell.execute_reply.started":"2024-03-27T11:52:11.101987Z","shell.execute_reply":"2024-03-27T11:52:11.117349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\n# Assuming you have NLTK installed, if not, install it using:\nimport nltk\nnltk.download('stopwords')\nnltk.download('punkt')\n\n# Function to preprocess text data\ndef preprocess_text(text):\n    # Convert text to lowercase\n    text = text.lower()\n    # Remove URLs\n    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n    # Remove special characters and punctuation\n    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n    # Remove stopwords\n    stop_words = set(stopwords.words('english'))\n    word_tokens = word_tokenize(text)\n    filtered_text = [word for word in word_tokens if word not in stop_words]\n    # Join the words back into a string\n    text = ' '.join(filtered_text)\n    return text\n\n\n\n# Model training and evaluation steps...\n","metadata":{"execution":{"iopub.status.busy":"2024-03-27T11:52:13.859166Z","iopub.execute_input":"2024-03-27T11:52:13.859793Z","iopub.status.idle":"2024-03-27T11:52:14.416218Z","shell.execute_reply.started":"2024-03-27T11:52:13.859765Z","shell.execute_reply":"2024-03-27T11:52:14.415348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocess the tweets\nX_train_preprocessed = X_train.apply(preprocess_text)\nX_test_preprocessed = X_test.apply(preprocess_text)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-27T11:52:20.787197Z","iopub.execute_input":"2024-03-27T11:52:20.787543Z","iopub.status.idle":"2024-03-27T11:52:29.996685Z","shell.execute_reply.started":"2024-03-27T11:52:20.787517Z","shell.execute_reply":"2024-03-27T11:52:29.995636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data cleaning and preprocessing\n\n\n\n# TF-IDF Vectorization\ntfidf_vectorizer = TfidfVectorizer(max_features=5000)\nX_train_tfidf = tfidf_vectorizer.fit_transform(X_train_preprocessed)\nX_test_tfidf = tfidf_vectorizer.transform(X_test_preprocessed)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-27T11:52:34.479504Z","iopub.execute_input":"2024-03-27T11:52:34.480375Z","iopub.status.idle":"2024-03-27T11:52:34.960348Z","shell.execute_reply.started":"2024-03-27T11:52:34.480335Z","shell.execute_reply":"2024-03-27T11:52:34.95928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Train Decision Tree\ndt_classifier = DecisionTreeClassifier()\ndt_classifier.fit(X_train_tfidf, y_train)\ndt_preds = dt_classifier.predict(X_test_tfidf)\ndt_accuracy = accuracy_score(y_test, dt_preds)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-13T08:30:30.151682Z","iopub.execute_input":"2024-03-13T08:30:30.151965Z","iopub.status.idle":"2024-03-13T08:30:32.20888Z","shell.execute_reply.started":"2024-03-13T08:30:30.151941Z","shell.execute_reply":"2024-03-13T08:30:32.208064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dt_accuracy","metadata":{"execution":{"iopub.status.busy":"2024-03-13T08:30:32.210055Z","iopub.execute_input":"2024-03-13T08:30:32.21036Z","iopub.status.idle":"2024-03-13T08:30:32.214478Z","shell.execute_reply.started":"2024-03-13T08:30:32.210333Z","shell.execute_reply":"2024-03-13T08:30:32.213413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Define the parameter grid to search\nparam_grid = {\n    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n    'max_depth': [None, 10, 20],       # Maximum depth of the trees\n    'min_samples_split': [2, 5, 10],   # Minimum number of samples required to split an internal node\n    'min_samples_leaf': [1, 2, 4]      # Minimum number of samples required to be at a leaf node\n}\n\n# Create a Random Forest classifier\nrf_classifier = RandomForestClassifier()\n\n# Grid search with cross-validation\ngrid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\ngrid_search.fit(X_train_tfidf, y_train)\n\n# Best hyperparameters\nbest_params = grid_search.best_params_\nprint(\"Best Hyperparameters:\", best_params)\n\n# Evaluate the best model\nbest_rf_model = grid_search.best_estimator_\nbest_rf_model_preds = best_rf_model.predict(X_test_tfidf)\nbest_rf_model_accuracy = accuracy_score(y_test, best_rf_model_preds)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-26T10:36:59.510531Z","iopub.execute_input":"2024-03-26T10:36:59.510882Z","iopub.status.idle":"2024-03-26T10:49:00.256726Z","shell.execute_reply.started":"2024-03-26T10:36:59.510856Z","shell.execute_reply":"2024-03-26T10:49:00.255631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_rf_model_accuracy","metadata":{"execution":{"iopub.status.busy":"2024-03-26T10:50:35.125464Z","iopub.execute_input":"2024-03-26T10:50:35.126423Z","iopub.status.idle":"2024-03-26T10:50:35.133638Z","shell.execute_reply.started":"2024-03-26T10:50:35.126381Z","shell.execute_reply":"2024-03-26T10:50:35.132778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n\n# Assuming lr_preds and y_test are already defined\nimport pandas as pd\nimport numpy as np\n# Assuming lr_preds and y_test are already defined\nconf_matrix = confusion_matrix(y_test, best_rf_model_preds)\naccuracy = accuracy_score(y_test, best_rf_model_preds)\nprecision = precision_score(y_test, best_rf_model_preds, average='weighted')\nrecall = recall_score(y_test, best_rf_model_preds, average='weighted')\nf1score = f1_score(y_test, best_rf_model_preds, average='weighted')\n\n# Calculate total for each row and column\nconf_matrix_with_total = conf_matrix.copy()\nconf_matrix_with_total = np.append(conf_matrix_with_total, [np.sum(conf_matrix_with_total, axis=0)], axis=0)\nconf_matrix_with_total = np.append(conf_matrix_with_total, np.sum(conf_matrix_with_total, axis=1).reshape(-1, 1), axis=1)\n\n# Create a DataFrame for the confusion matrix\nconf_matrix_df = pd.DataFrame(conf_matrix_with_total, \n                               index=['Hate Speech', 'Offensive', 'Neither', 'Total'], \n                               columns=['Predicted 0', 'Predicted 1', 'Predicted 2', 'Total'])\n\n# Create a DataFrame for the score metrics\nscore_metrics_df = pd.DataFrame({'Accuracy': [accuracy],\n                                 'Precision': [precision],\n                                 'Recall': [recall],\n                                 'F1 Score': [f1score]})\n\nprint(\"Confusion Matrix:\")\nprint(conf_matrix_df)\nprint(\"\\nScore Metrics:\")\nprint(score_metrics_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-26T10:52:30.313044Z","iopub.execute_input":"2024-03-26T10:52:30.313426Z","iopub.status.idle":"2024-03-26T10:52:30.349012Z","shell.execute_reply.started":"2024-03-26T10:52:30.313396Z","shell.execute_reply":"2024-03-26T10:52:30.348047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_rf_model_accuracy","metadata":{"execution":{"iopub.status.busy":"2024-03-13T08:42:25.819766Z","iopub.execute_input":"2024-03-13T08:42:25.82011Z","iopub.status.idle":"2024-03-13T08:42:25.828266Z","shell.execute_reply.started":"2024-03-13T08:42:25.820076Z","shell.execute_reply":"2024-03-13T08:42:25.827237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train Random Forest\n# rf_classifier = RandomForestClassifier()\n# rf_classifier.fit(X_train_tfidf, y_train)\n# rf_preds = rf_classifier.predict(X_test_tfidf)\n# rf_accuracy = accuracy_score(y_test, rf_preds)\n\n# Train Logistic Regression\nlr_classifier = LogisticRegression(max_iter=1000)\nlr_classifier.fit(X_train_tfidf, y_train)\nlr_preds = lr_classifier.predict(X_test_tfidf)\nlr_accuracy = accuracy_score(y_test, lr_preds)\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:28:13.8237Z","iopub.execute_input":"2024-03-20T15:28:13.824055Z","iopub.status.idle":"2024-03-20T15:28:15.002521Z","shell.execute_reply.started":"2024-03-20T15:28:13.824027Z","shell.execute_reply":"2024-03-20T15:28:15.0011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\n# Define the logistic regression classifier\nlr_classifier = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs')\n\n# Define the hyperparameters grid\nparam_grid = {\n    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization parameter\n    'penalty': ['l2'],                     # L2 regularization only for multinomial\n    'class_weight': [None, 'balanced'],    # Weights associated with classes\n    'fit_intercept': [True, False],        # Whether to calculate the intercept\n}\n\n# Perform grid search with 5-fold cross-validation\ngrid_search = GridSearchCV(estimator=lr_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\ngrid_search.fit(X_train_tfidf, y_train)\n\n# Get the best hyperparameters\nbest_params = grid_search.best_params_\n\n# Train a new logistic regression classifier using the best hyperparameters\nbest_lr_classifier = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs', **best_params)\nbest_lr_classifier.fit(X_train_tfidf, y_train)\n\n# Make predictions on the test set using the best classifier\nbest_lr_preds = best_lr_classifier.predict(X_test_tfidf)\n\n# Calculate accuracy\nbest_lr_accuracy = accuracy_score(y_test, best_lr_preds)\n\nprint(\"Best Hyperparameters:\", best_params)\nprint(\"Accuracy with Best Hyperparameters:\", best_lr_accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-26T13:45:40.165594Z","iopub.execute_input":"2024-03-26T13:45:40.165991Z","iopub.status.idle":"2024-03-26T13:47:43.694343Z","shell.execute_reply.started":"2024-03-26T13:45:40.165963Z","shell.execute_reply":"2024-03-26T13:47:43.693281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n\n# Assuming lr_preds and y_test are already defined\nimport pandas as pd\nimport numpy as np\n# Assuming lr_preds and y_test are already defined\nconf_matrix = confusion_matrix(y_test, best_lr_preds)\naccuracy = accuracy_score(y_test, best_lr_preds)\nprecision = precision_score(y_test, best_lr_preds, average='weighted')\nrecall = recall_score(y_test, best_lr_preds, average='weighted')\nf1score = f1_score(y_test, best_lr_preds, average='weighted')\n\n# Calculate total for each row and column\nconf_matrix_with_total = conf_matrix.copy()\nconf_matrix_with_total = np.append(conf_matrix_with_total, [np.sum(conf_matrix_with_total, axis=0)], axis=0)\nconf_matrix_with_total = np.append(conf_matrix_with_total, np.sum(conf_matrix_with_total, axis=1).reshape(-1, 1), axis=1)\n\n# Create a DataFrame for the confusion matrix\nconf_matrix_df = pd.DataFrame(conf_matrix_with_total, \n                               index=['Hate Speech', 'Offensive', 'Neither', 'Total'], \n                               columns=['Predicted 0', 'Predicted 1', 'Predicted 2', 'Total'])\n\n# Create a DataFrame for the score metrics\nscore_metrics_df = pd.DataFrame({'Accuracy': [accuracy],\n                                 'Precision': [precision],\n                                 'Recall': [recall],\n                                 'F1 Score': [f1score]})\n\nprint(\"Confusion Matrix:\")\nprint(conf_matrix_df)\nprint(\"\\nScore Metrics:\")\nprint(score_metrics_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-26T10:06:40.995243Z","iopub.execute_input":"2024-03-26T10:06:40.995599Z","iopub.status.idle":"2024-03-26T10:06:41.030016Z","shell.execute_reply.started":"2024-03-26T10:06:40.995568Z","shell.execute_reply":"2024-03-26T10:06:41.028949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_accuracy","metadata":{"execution":{"iopub.status.busy":"2024-03-13T08:42:27.077044Z","iopub.execute_input":"2024-03-13T08:42:27.080714Z","iopub.status.idle":"2024-03-13T08:42:27.09384Z","shell.execute_reply.started":"2024-03-13T08:42:27.08066Z","shell.execute_reply":"2024-03-13T08:42:27.092503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.model_selection import GridSearchCV\n# from sklearn.metrics import accuracy_score\n# from sklearn.tree import DecisionTreeClassifier\n\n# # Create an instance of the Decision Tree Classifier\n# dt_classifier = DecisionTreeClassifier()\n\n# # Define the parameter grid to search\n# param_grid = {\n#     'max_depth': [None, 5, 10, 15],                 # Maximum depth of the tree\n#     'min_samples_split': [2, 5, 10],                 # Minimum number of samples required to split an internal node\n#     'min_samples_leaf': [1, 2, 4],                  # Minimum number of samples required to be at a leaf node\n#     'max_features': ['auto', 'sqrt', 'log2', None]  # Number of features to consider when looking for the best split\n# }\n\n# # Initialize GridSearchCV\n# grid_search = GridSearchCV(estimator=dt_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n\n# # Perform Grid Search cross-validation\n# grid_search.fit(X_train_tfidf, y_train)\n\n# # Get the best hyperparameters\n# best_params = grid_search.best_params_\n\n# # Train Decision Tree with the best hyperparameters\n# best_dt_classifier = DecisionTreeClassifier(**best_params)\n# best_dt_classifier.fit(X_train_tfidf, y_train)\n\n# # Make predictions\n# dt_preds = best_dt_classifier.predict(X_test_tfidf)\n\n# # Calculate accuracy\n# dt_accuracy = accuracy_score(y_test, dt_preds)\n# print(\"Accuracy:\", dt_accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-13T08:42:27.099964Z","iopub.execute_input":"2024-03-13T08:42:27.103057Z","iopub.status.idle":"2024-03-13T08:42:27.113132Z","shell.execute_reply.started":"2024-03-13T08:42:27.10301Z","shell.execute_reply":"2024-03-13T08:42:27.111805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import SVC\n\n# Train SVM\nsvm_classifier = SVC(kernel='linear')\nsvm_classifier.fit(X_train_tfidf, y_train)\nsvm_preds = svm_classifier.predict(X_test_tfidf)\nsvm_accuracy = accuracy_score(y_test, svm_preds)","metadata":{"execution":{"iopub.status.busy":"2024-03-26T11:56:59.260261Z","iopub.execute_input":"2024-03-26T11:56:59.260905Z","iopub.status.idle":"2024-03-26T11:57:13.548453Z","shell.execute_reply.started":"2024-03-26T11:56:59.260877Z","shell.execute_reply":"2024-03-26T11:57:13.547408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n\n# Assuming lr_preds and y_test are already defined\nimport pandas as pd\nimport numpy as np\n# Assuming lr_preds and y_test are already defined\nconf_matrix = confusion_matrix(y_test, svm_preds)\naccuracy = accuracy_score(y_test, svm_preds)\nprecision = precision_score(y_test, svm_preds, average='weighted')\nrecall = recall_score(y_test, svm_preds, average='weighted')\nf1score = f1_score(y_test, svm_preds, average='weighted')\n\n# Calculate total for each row and column\nconf_matrix_with_total = conf_matrix.copy()\nconf_matrix_with_total = np.append(conf_matrix_with_total, [np.sum(conf_matrix_with_total, axis=0)], axis=0)\nconf_matrix_with_total = np.append(conf_matrix_with_total, np.sum(conf_matrix_with_total, axis=1).reshape(-1, 1), axis=1)\n\n# Create a DataFrame for the confusion matrix\nconf_matrix_df = pd.DataFrame(conf_matrix_with_total, \n                               index=['Hate Speech', 'Offensive', 'Neither', 'Total'], \n                               columns=['Predicted 0', 'Predicted 1', 'Predicted 2', 'Total'])\n\n# Create a DataFrame for the score metrics\nscore_metrics_df = pd.DataFrame({'Accuracy': [accuracy],\n                                 'Precision': [precision],\n                                 'Recall': [recall],\n                                 'F1 Score': [f1score]})\n\nprint(\"Confusion Matrix:\")\nprint(conf_matrix_df)\nprint(\"\\nScore Metrics:\")\nprint(score_metrics_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-26T11:57:24.395896Z","iopub.execute_input":"2024-03-26T11:57:24.396761Z","iopub.status.idle":"2024-03-26T11:57:24.428005Z","shell.execute_reply.started":"2024-03-26T11:57:24.396728Z","shell.execute_reply":"2024-03-26T11:57:24.427092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ## bagging and boosting\n# from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier\n# from sklearn.metrics import accuracy_score\n# from sklearn.svm import SVC\n# base_dt_classifier = DecisionTreeClassifier()\n\n# # Create base SVM classifier\n# # base_svm_classifier = SVC(kernel='sigmoid')\n\n# # AdaBoost\n# adaboost_classifier = AdaBoostClassifier(base_estimator=base_dt_classifier,n_estimators=50, learning_rate=1.0)\n# adaboost_classifier.fit(X_train_tfidf, y_train)\n# adaboost_preds = adaboost_classifier.predict(X_test_tfidf)\n# adaboost_accuracy = accuracy_score(y_test, adaboost_preds)\n# print(\"AdaBoost Accuracy:\", adaboost_accuracy)\n\n# # Bagging\n# bagging_classifier = BaggingClassifier(base_estimator=base_dt_classifier, n_estimators=50, max_samples=1.0, max_features=1.0, bootstrap=True, bootstrap_features=False)\n# bagging_classifier.fit(X_train_tfidf, y_train)\n# bagging_preds = bagging_classifier.predict(X_test_tfidf)\n# bagging_accuracy = accuracy_score(y_test, bagging_preds)\n# print(\"Bagging Accuracy:\", bagging_accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-13T08:42:42.295309Z","iopub.execute_input":"2024-03-13T08:42:42.295758Z","iopub.status.idle":"2024-03-13T08:42:42.302044Z","shell.execute_reply.started":"2024-03-13T08:42:42.295724Z","shell.execute_reply":"2024-03-13T08:42:42.301232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm_accuracy","metadata":{"execution":{"iopub.status.busy":"2024-03-13T08:42:42.3032Z","iopub.execute_input":"2024-03-13T08:42:42.303851Z","iopub.status.idle":"2024-03-13T08:42:42.313056Z","shell.execute_reply.started":"2024-03-13T08:42:42.303818Z","shell.execute_reply":"2024-03-13T08:42:42.312169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\n# Create and train KNN classifier\nknn_classifier = KNeighborsClassifier(n_neighbors=2)  # You can adjust the number of neighbors (n_neighbors)\nknn_classifier.fit(X_train_tfidf, y_train)\n\n# Predict on test set\nknn_preds = knn_classifier.predict(X_test_tfidf)\n\n# Calculate accuracy\nknn_accuracy = accuracy_score(y_test, knn_preds)\nprint(\"KNN Accuracy:\", knn_accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-26T12:06:43.155156Z","iopub.execute_input":"2024-03-26T12:06:43.155511Z","iopub.status.idle":"2024-03-26T12:06:47.409102Z","shell.execute_reply.started":"2024-03-26T12:06:43.155487Z","shell.execute_reply":"2024-03-26T12:06:47.4081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-03-26T12:12:46.376384Z","iopub.execute_input":"2024-03-26T12:12:46.377387Z","iopub.status.idle":"2024-03-26T12:12:46.656384Z","shell.execute_reply.started":"2024-03-26T12:12:46.377353Z","shell.execute_reply":"2024-03-26T12:12:46.655428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n\n# Assuming lr_preds and y_test are already defined\nimport pandas as pd\nimport numpy as np\n# Assuming lr_preds and y_test are already defined\nconf_matrix = confusion_matrix(y_test, knn_preds)\naccuracy = accuracy_score(y_test, knn_preds)\nprecision = precision_score(y_test, knn_preds, average='weighted')\nrecall = recall_score(y_test, knn_preds, average='weighted')\nf1score = f1_score(y_test, knn_preds, average='weighted')\n\n# Calculate total for each row and column\nconf_matrix_with_total = conf_matrix.copy()\nconf_matrix_with_total = np.append(conf_matrix_with_total, [np.sum(conf_matrix_with_total, axis=0)], axis=0)\nconf_matrix_with_total = np.append(conf_matrix_with_total, np.sum(conf_matrix_with_total, axis=1).reshape(-1, 1), axis=1)\n\n# Create a DataFrame for the confusion matrix\nconf_matrix_df = pd.DataFrame(conf_matrix_with_total, \n                               index=['Hate Speech', 'Offensive', 'Neither', 'Total'], \n                               columns=['Predicted 0', 'Predicted 1', 'Predicted 2', 'Total'])\n\n# Create a DataFrame for the score metrics\nscore_metrics_df = pd.DataFrame({'Accuracy': [accuracy],\n                                 'Precision': [precision],\n                                 'Recall': [recall],\n                                 'F1 Score': [f1score]})\n\nprint(\"Confusion Matrix:\")\nprint(conf_matrix_df)\nprint(\"\\nScore Metrics:\")\nprint(score_metrics_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-26T12:08:28.076842Z","iopub.execute_input":"2024-03-26T12:08:28.077205Z","iopub.status.idle":"2024-03-26T12:08:28.107771Z","shell.execute_reply.started":"2024-03-26T12:08:28.077176Z","shell.execute_reply":"2024-03-26T12:08:28.106814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\n\n# Define the Multinomial Naive Bayes classifier\nnb_classifier = MultinomialNB()\n\n# Define the hyperparameter grid\nparam_grid = {\n    'alpha': [0.1, 0.5, 1.0],  # Add more values if needed\n    'fit_prior': [True, False]\n}\n\n# Initialize GridSearchCV\ngrid_search = GridSearchCV(estimator=nb_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n\n# Perform Grid Search\ngrid_search.fit(X_train_tfidf, y_train)\n\n# Get the best hyperparameters\nbest_params = grid_search.best_params_\n\n# Initialize Multinomial Naive Bayes classifier with the best hyperparameters\nbest_nb_classifier = MultinomialNB(**best_params)\n\n# Train the best classifier on the entire training set\nbest_nb_classifier.fit(X_train_tfidf, y_train)\n\n# Make predictions on the test set\nnb_preds = best_nb_classifier.predict(X_test_tfidf)\n\n# Calculate accuracy\nnb_accuracy = accuracy_score(y_test, nb_preds)\n\nprint(\"Best Hyperparameters:\", best_params)\nprint(\"Accuracy with Best Hyperparameters:\", nb_accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-26T12:15:32.994952Z","iopub.execute_input":"2024-03-26T12:15:32.995334Z","iopub.status.idle":"2024-03-26T12:15:33.252985Z","shell.execute_reply.started":"2024-03-26T12:15:32.995304Z","shell.execute_reply":"2024-03-26T12:15:33.252076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n\n# Assuming lr_preds and y_test are already defined\nimport pandas as pd\nimport numpy as np\n# Assuming lr_preds and y_test are already defined\nconf_matrix = confusion_matrix(y_test, nb_preds)\naccuracy = accuracy_score(y_test, nb_preds)\nprecision = precision_score(y_test, nb_preds, average='weighted')\nrecall = recall_score(y_test, nb_preds, average='weighted')\nf1score = f1_score(y_test, nb_preds, average='weighted')\n\n# Calculate total for each row and column\nconf_matrix_with_total = conf_matrix.copy()\nconf_matrix_with_total = np.append(conf_matrix_with_total, [np.sum(conf_matrix_with_total, axis=0)], axis=0)\nconf_matrix_with_total = np.append(conf_matrix_with_total, np.sum(conf_matrix_with_total, axis=1).reshape(-1, 1), axis=1)\n\n# Create a DataFrame for the confusion matrix\nconf_matrix_df = pd.DataFrame(conf_matrix_with_total, \n                               index=['Hate Speech', 'Offensive', 'Neither', 'Total'], \n                               columns=['Predicted 0', 'Predicted 1', 'Predicted 2', 'Total'])\n\n# Create a DataFrame for the score metrics\nscore_metrics_df = pd.DataFrame({'Accuracy': [accuracy],\n                                 'Precision': [precision],\n                                 'Recall': [recall],\n                                 'F1 Score': [f1score]})\n\nprint(\"Confusion Matrix:\")\nprint(conf_matrix_df)\nprint(\"\\nScore Metrics:\")\nprint(score_metrics_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-26T12:15:36.38844Z","iopub.execute_input":"2024-03-26T12:15:36.388782Z","iopub.status.idle":"2024-03-26T12:15:36.424478Z","shell.execute_reply.started":"2024-03-26T12:15:36.388756Z","shell.execute_reply":"2024-03-26T12:15:36.423583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-03-13T08:43:45.30988Z","iopub.execute_input":"2024-03-13T08:43:45.310352Z","iopub.status.idle":"2024-03-13T08:44:21.700253Z","shell.execute_reply.started":"2024-03-13T08:43:45.310319Z","shell.execute_reply":"2024-03-13T08:44:21.699113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install spacy\n#python -m spacy download en_core_web_sm\nimport spacy\n\n# Load English language model\nnlp = spacy.load('en_core_web_sm')\n\n# Define a function for preprocessing text with lemmatization\ndef preprocess_text_with_lemmatization(tweet):\n    # Remove special characters, URLs, and mentions\n    tweet = re.sub(r'http\\S+|www\\S+|pic.twitter\\S+|@\\S+', '', tweet)\n    tweet = re.sub(r'[^a-zA-Z\\s]', '', tweet)\n    \n    # Remove extra spaces and convert to lowercase\n    tweet = ' '.join(tweet.lower().split())\n    \n    # Lemmatize the text\n    lemmatized_tokens = []\n    doc = nlp(tweet)\n    for token in doc:\n        lemmatized_tokens.append(token.lemma_)\n    \n    # Join lemmatized tokens back into a single string\n    tweet = ' '.join(lemmatized_tokens)\n    \n    return tweet\n","metadata":{"execution":{"iopub.status.busy":"2024-03-26T12:43:39.837101Z","iopub.execute_input":"2024-03-26T12:43:39.838068Z","iopub.status.idle":"2024-03-26T12:44:02.249944Z","shell.execute_reply.started":"2024-03-26T12:43:39.838036Z","shell.execute_reply":"2024-03-26T12:44:02.249051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.layers import LSTM, Dropout\n\n\n## X = data['tweet']\ny = data['class']\nX = data['tweet'].apply(preprocess_text_with_lemmatization)\n#X_test_preprocessed = X_test.apply(preprocess_text)\n\n\n\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(X)\nsequences = tokenizer.texts_to_sequences(X)\n\n# Pad sequences\nmax_len = 20  # Max sequence length\nX_padded = pad_sequences(sequences, maxlen=max_len)\n\n# Split data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.20, random_state=42)\n\n# Define LSTM model\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_len),\n    tf.keras.layers.LSTM(64),\n    tf.keras.layers.Dense(3, activation='softmax')  # 3 output classes\n])\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n\n# Train the model with early stopping\nmodel.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n\n# Evaluate the model on the test set\n_, test_accuracy = model.evaluate(X_test, y_test)\nprint(\"Test Accuracy:\", test_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-03-26T12:44:29.065457Z","iopub.execute_input":"2024-03-26T12:44:29.066202Z","iopub.status.idle":"2024-03-26T12:47:51.891268Z","shell.execute_reply.started":"2024-03-26T12:44:29.066171Z","shell.execute_reply":"2024-03-26T12:47:51.89028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.layers import LSTM, Dropout\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_len),  # Increase output_dim\n    tf.keras.layers.LSTM(64, return_sequences=True),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.LSTM(64),\n    tf.keras.layers.Dense(3, activation='softmax')\n])\n\n# X = data['tweet']\ny = data['class']\nX = data['tweet'].apply(preprocess_text_with_lemmatization)\n#X_test_preprocessed = X_test.apply(preprocess_text)\n\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(X)\nsequences = tokenizer.texts_to_sequences(X)\n\n# Pad sequences\nmax_len = 20  # Max sequence length\nX_padded = pad_sequences(sequences, maxlen=max_len)\n\n# Learning rate scheduler\ndef lr_scheduler(epoch, lr):\n    if epoch % 10 == 0 and epoch != 0:\n        lr = lr * 0.9  # Decrease learning rate by 10% every 10 epochs\n    return lr\n\noptimizer = Adam(learning_rate=0.001)  # Set initial learning rate\n\n# Compile the model with custom optimizer and loss\nmodel.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Learning rate scheduler callback\nlr_callback = LearningRateScheduler(lr_scheduler)\n\n# Train the model with early stopping and learning rate scheduler\nmodel.fit(X_train, y_train, epochs=30, batch_size=16, validation_split=0.2, callbacks=[early_stopping, lr_callback])\n\n\n# Evaluate the model on the test set\n_, test_accuracy = model.evaluate(X_test, y_test)\nprint(\"Test Accuracy:\", test_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-03-26T13:23:41.325838Z","iopub.execute_input":"2024-03-26T13:23:41.326266Z","iopub.status.idle":"2024-03-26T13:27:11.159766Z","shell.execute_reply.started":"2024-03-26T13:23:41.326237Z","shell.execute_reply":"2024-03-26T13:27:11.15875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n\n# Make predictions on the test set\n# Make predictions on the test set\ny_pred_probs = model.predict(X_test)\ny_pred = np.argmax(y_pred_probs, axis=1)\n\n# Compute precision, recall, and F1-score\nprecision = precision_score(y_test, y_pred, average='macro')\nrecall = recall_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\n\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)\nprint(\"F1-score:\", f1)\n\n# Compute confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-26T13:30:09.190716Z","iopub.execute_input":"2024-03-26T13:30:09.191453Z","iopub.status.idle":"2024-03-26T13:30:10.474584Z","shell.execute_reply.started":"2024-03-26T13:30:09.191421Z","shell.execute_reply":"2024-03-26T13:30:10.473564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Custom voting mechanism\nvoting_preds = []\nfor i in range(len(best_rf_model_preds)):\n    # Combine predictions from all classifiers\n    predictions = [best_rf_model_preds[i], best_lr_preds[i], svm_preds[i], knn_preds[i], nb_preds[i], y_pred[i]]\n    # Take majority vote\n    majority_vote = max(set(predictions), key=predictions.count)\n    voting_preds.append(majority_vote)\n\n# Calculate accuracy\nvoting_accuracy = accuracy_score(y_test, voting_preds)\nprint(\"Voting Classifier Accuracy:\", voting_accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-26T13:55:51.127482Z","iopub.execute_input":"2024-03-26T13:55:51.127903Z","iopub.status.idle":"2024-03-26T13:55:51.154483Z","shell.execute_reply.started":"2024-03-26T13:55:51.127875Z","shell.execute_reply":"2024-03-26T13:55:51.153452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n\n# Assuming lr_preds and y_test are already defined\nimport pandas as pd\nimport numpy as np\n# Assuming lr_preds and y_test are already defined\nconf_matrix = confusion_matrix(y_test, voting_preds)\naccuracy = accuracy_score(y_test, voting_preds)\nprecision = precision_score(y_test, voting_preds, average='weighted')\nrecall = recall_score(y_test, voting_preds, average='weighted')\nf1score = f1_score(y_test, voting_preds, average='weighted')\n\n# Calculate total for each row and column\nconf_matrix_with_total = conf_matrix.copy()\nconf_matrix_with_total = np.append(conf_matrix_with_total, [np.sum(conf_matrix_with_total, axis=0)], axis=0)\nconf_matrix_with_total = np.append(conf_matrix_with_total, np.sum(conf_matrix_with_total, axis=1).reshape(-1, 1), axis=1)\n\n# Create a DataFrame for the confusion matrix\nconf_matrix_df = pd.DataFrame(conf_matrix_with_total, \n                               index=['Hate Speech', 'Offensive', 'Neither', 'Total'], \n                               columns=['Predicted 0', 'Predicted 1', 'Predicted 2', 'Total'])\n\n# Create a DataFrame for the score metrics\nscore_metrics_df = pd.DataFrame({'Accuracy': [accuracy],\n                                 'Precision': [precision],\n                                 'Recall': [recall],\n                                 'F1 Score': [f1score]})\n\nprint(\"Confusion Matrix:\")\nprint(conf_matrix_df)\nprint(\"\\nScore Metrics:\")\nprint(score_metrics_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-26T13:56:01.213278Z","iopub.execute_input":"2024-03-26T13:56:01.213642Z","iopub.status.idle":"2024-03-26T13:56:01.256244Z","shell.execute_reply.started":"2024-03-26T13:56:01.213616Z","shell.execute_reply":"2024-03-26T13:56:01.255276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom transformers import BertTokenizer, TFBertForSequenceClassification\nfrom tensorflow.keras.optimizers import Adam\nimport numpy as np\nfrom tensorflow.keras.callbacks import EarlyStopping\n# Load your dataset\ndata = pd.read_csv('/kaggle/input/datset15/labeled_data.csv')  # Update with your file path\nX = data['tweet']\ny = data['class']\n\n# Tokenize text data\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nX_encoded = tokenizer(X.tolist(), padding=True, truncation=True, max_length=64, return_tensors='tf')['input_ids']\n\n# Convert the tensor to a numpy array\nX_encoded = np.array(X_encoded)\n\n# Split data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n\n# model.trainable = True\n# for layer in model.layers[:-4]:\n#     layer.trainable = False\n\n# Learning rate scheduling\n# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n#     initial_learning_rate=3e-5,\n#     decay_steps=10000,\n#     decay_rate=0.9\n# )\n\n# Define optimizer with learning rate scheduling\n# optimizer = Adam(learning_rate=lr_schedule)\n\n# Load the pre-trained BERT model for sequence classification\nmodel = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)  # Assuming 3 output classes\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3)  # Stop training when validation loss stops decreasing for 3 epochs\n# Compile the model\noptimizer = Adam(learning_rate=3e-5)\n# Compile the model with optimizer\nmodel.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n\n# Train the model with early stopping and learning rate scheduling\nmodel.fit(X_train, y_train, epochs=20, batch_size=16, validation_split=0.2, callbacks=[early_stopping])\n\n# Evaluate the model on the test set\nloss, accuracy = model.evaluate(X_test, y_test)\nprint(\"Test Loss:\", loss)\nprint(\"Test Accuracy:\", accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-03T17:59:31.552582Z","iopub.execute_input":"2024-04-03T17:59:31.553258Z","iopub.status.idle":"2024-04-03T18:12:36.559088Z","shell.execute_reply.started":"2024-04-03T17:59:31.553226Z","shell.execute_reply":"2024-04-03T18:12:36.557929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\n\n# Save the model to a file in the working directory\nfilename = '/kaggle/working/model_save2'\nwith open(filename, 'wb') as file:\n    pickle.dump(model, file)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-03T18:47:50.350877Z","iopub.execute_input":"2024-04-03T18:47:50.351656Z","iopub.status.idle":"2024-04-03T18:47:56.957294Z","shell.execute_reply.started":"2024-04-03T18:47:50.351624Z","shell.execute_reply":"2024-04-03T18:47:56.956402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import BertForSequenceClassification, BertTokenizer\nimport torch\n\n# Load the model and tokenizer from the saved directory\nmodel = BertForSequenceClassification.from_pretrained('/kaggle/working/my_bert_model',from_tf=True)\ntokenizer = BertTokenizer.from_pretrained('/kaggle/working/my_bert_model')\n\n# Test the model and tokenizer\ntext = \"Hello, world!\"\ninputs = tokenizer(text, return_tensors='pt')\nwith torch.no_grad():\n    outputs = model(**inputs)\n\n# The outputs are logits; to convert to probabilities, apply the softmax function\nlogits = outputs.logits\nprobabilities = torch.nn.functional.softmax(logits, dim=1)\n\n# Get the predicted class (the one with the highest probability)\npredicted_class = probabilities.argmax(dim=1)\n\nprint(predicted_class)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:42:37.208201Z","iopub.execute_input":"2024-04-03T19:42:37.208588Z","iopub.status.idle":"2024-04-03T19:42:39.612869Z","shell.execute_reply.started":"2024-04-03T19:42:37.20856Z","shell.execute_reply":"2024-04-03T19:42:39.61172Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stderr","text":"All TF 2.0 model weights were used when initializing BertForSequenceClassification.\n\nAll the weights of BertForSequenceClassification were initialized from the TF 2.0 model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"tensor([2])\n","output_type":"stream"}]},{"cell_type":"code","source":"!zip -r Bert_model.zip /kaggle/working/my_bert_model\n","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:46:43.054103Z","iopub.execute_input":"2024-04-03T19:46:43.054604Z","iopub.status.idle":"2024-04-03T19:47:24.310417Z","shell.execute_reply.started":"2024-04-03T19:46:43.054563Z","shell.execute_reply":"2024-04-03T19:47:24.309222Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"  adding: kaggle/working/my_bert_model/ (stored 0%)\n  adding: kaggle/working/my_bert_model/config.json (deflated 50%)\n  adding: kaggle/working/my_bert_model/special_tokens_map.json (deflated 42%)\n  adding: kaggle/working/my_bert_model/tf_model.h5 (deflated 8%)\n  adding: kaggle/working/my_bert_model/tokenizer_config.json (deflated 75%)\n  adding: kaggle/working/my_bert_model/outputname.tar.gz (deflated 0%)\n  adding: kaggle/working/my_bert_model/vocab.txt (deflated 53%)\n","output_type":"stream"}]},{"cell_type":"code","source":"!tar -zcvf outputname.tar.gz /kaggle/working/my_bert_model.zip","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:39:18.023079Z","iopub.execute_input":"2024-04-03T19:39:18.023692Z","iopub.status.idle":"2024-04-03T19:39:34.535444Z","shell.execute_reply.started":"2024-04-03T19:39:18.023651Z","shell.execute_reply":"2024-04-03T19:39:34.534165Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"tar: Removing leading `/' from member names\n/kaggle/working/my_bert_model.zip\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score\n\n# Make predictions on the test set\ny_pred_probs = model.predict(X_test)\ny_pred = np.argmax(y_pred_probs.logits, axis=1)\n\n# Compute confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# Compute F1-score\nf1 = f1_score(y_test, y_pred, average='macro')\nprint(\"F1-score:\", f1)\n\n# Compute recall\nrecall = recall_score(y_test, y_pred, average='macro')\nprint(\"Recall:\", recall)\n\n# Compute precision\nprecision = precision_score(y_test, y_pred, average='macro')\nprint(\"Precision:\", precision)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-27T12:29:10.333885Z","iopub.execute_input":"2024-03-27T12:29:10.334638Z","iopub.status.idle":"2024-03-27T12:29:27.508946Z","shell.execute_reply.started":"2024-03-27T12:29:10.334604Z","shell.execute_reply":"2024-03-27T12:29:27.507831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" threshold = 0.5  # Adjust this threshold based on your requirements\n\n# Obtain predicted logits from the model\ny_pred_probs = model.predict(X_test)\ny_pred_logits = np.argmax(y_pred_probs.logits, axis=1)\n\n# Convert predicted logits to labels based on threshold\nnew_labels = []\n\nfor logits in y_pred_probs.logits:\n    max_score_class = np.argmax(logits)\n    probs = np.exp(logits) / np.sum(np.exp(logits),  keepdims=True)   \n    # Split instances of classes 0 and 1 into sub-classes\n    if max_score_class==0:\n        if probs[0]<0.5:\n            new_labels.append(0)  # Offensive a\n        else:\n            new_labels.append(1)  # Offensive b\n    elif max_score_class==1:\n        if probs[1]<0.5:\n            new_labels.append(2)  # Hate speech a\n        else:\n            new_labels.append(3)  # Hate speech b\n    else:\n        new_labels.append(4)  # Neither\n\n# Convert new labels to array\nnew_labels = np.array(new_labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-27T15:19:25.148622Z","iopub.execute_input":"2024-03-27T15:19:25.148993Z","iopub.status.idle":"2024-03-27T15:19:42.182166Z","shell.execute_reply.started":"2024-03-27T15:19:25.148964Z","shell.execute_reply":"2024-03-27T15:19:42.181345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test","metadata":{"execution":{"iopub.status.busy":"2024-03-27T15:21:25.861025Z","iopub.execute_input":"2024-03-27T15:21:25.861424Z","iopub.status.idle":"2024-03-27T15:21:25.869904Z","shell.execute_reply.started":"2024-03-27T15:21:25.861394Z","shell.execute_reply":"2024-03-27T15:21:25.868819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" np.unique(new_labels)","metadata":{"execution":{"iopub.status.busy":"2024-03-27T15:20:27.062224Z","iopub.execute_input":"2024-03-27T15:20:27.06262Z","iopub.status.idle":"2024-03-27T15:20:27.069627Z","shell.execute_reply.started":"2024-03-27T15:20:27.062587Z","shell.execute_reply":"2024-03-27T15:20:27.068697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(new_labels)","metadata":{"execution":{"iopub.status.busy":"2024-03-27T15:22:48.972595Z","iopub.execute_input":"2024-03-27T15:22:48.973045Z","iopub.status.idle":"2024-03-27T15:22:48.97959Z","shell.execute_reply.started":"2024-03-27T15:22:48.973012Z","shell.execute_reply":"2024-03-27T15:22:48.978635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_test, new_labels, test_size=0.3, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-03-27T15:25:13.407464Z","iopub.execute_input":"2024-03-27T15:25:13.408296Z","iopub.status.idle":"2024-03-27T15:25:13.414262Z","shell.execute_reply.started":"2024-03-27T15:25:13.408261Z","shell.execute_reply":"2024-03-27T15:25:13.413341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.unique(y_train)","metadata":{"execution":{"iopub.status.busy":"2024-03-27T15:25:31.965888Z","iopub.execute_input":"2024-03-27T15:25:31.966607Z","iopub.status.idle":"2024-03-27T15:25:31.972716Z","shell.execute_reply.started":"2024-03-27T15:25:31.966577Z","shell.execute_reply":"2024-03-27T15:25:31.971807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Load the pre-trained BERT model for sequence classification\nmodel = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)  # Assuming 5 output classes\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3)  # Stop training when validation loss stops decreasing for 3 epochs\n# Compile the model\noptimizer = Adam(learning_rate=3e-5)\n# Compile the model with optimizer\nmodel.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n\n# Train the model with early stopping and learning rate scheduling\nmodel.fit(X_train, y_train, epochs=20, batch_size=16, validation_split=0.2, callbacks=[early_stopping])\n\n# Evaluate the model on the test set\nloss, accuracy = model.evaluate(X_test, y_test)\nprint(\"Test Loss:\", loss)\nprint(\"Test Accuracy:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-03-27T15:26:20.170143Z","iopub.execute_input":"2024-03-27T15:26:20.170906Z","iopub.status.idle":"2024-03-27T15:29:34.374797Z","shell.execute_reply.started":"2024-03-27T15:26:20.170875Z","shell.execute_reply":"2024-03-27T15:29:34.373852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.unique(y_test)","metadata":{"execution":{"iopub.status.busy":"2024-03-27T13:37:41.72978Z","iopub.execute_input":"2024-03-27T13:37:41.730592Z","iopub.status.idle":"2024-03-27T13:37:41.736871Z","shell.execute_reply.started":"2024-03-27T13:37:41.730558Z","shell.execute_reply":"2024-03-27T13:37:41.735938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score\n\n# Make predictions on the test set\ny_pred_probs = model.predict(X_test)\ny_pred = np.argmax(y_pred_probs.logits, axis=1)\n\n# Compute confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# Compute F1-score\nf1 = f1_score(y_test, y_pred, average='macro')\nprint(\"F1-score:\", f1)\n\n# Compute recall\nrecall = recall_score(y_test, y_pred, average='macro')\nprint(\"Recall:\", recall)\n\n# Compute precision\nprecision = precision_score(y_test, y_pred, average='macro')\nprint(\"Precision:\", precision)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-27T15:30:20.613952Z","iopub.execute_input":"2024-03-27T15:30:20.614373Z","iopub.status.idle":"2024-03-27T15:30:27.658064Z","shell.execute_reply.started":"2024-03-27T15:30:20.614341Z","shell.execute_reply":"2024-03-27T15:30:27.657164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.unique(y_test)","metadata":{"execution":{"iopub.status.busy":"2024-03-27T13:14:14.629729Z","iopub.execute_input":"2024-03-27T13:14:14.630361Z","iopub.status.idle":"2024-03-27T13:14:14.638619Z","shell.execute_reply.started":"2024-03-27T13:14:14.630328Z","shell.execute_reply":"2024-03-27T13:14:14.637655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n\nconf_matrix = confusion_matrix(y_test, y_pred)\n\n# Compute classification report (includes precision, recall, F1-score, and support)\ncls_report = classification_report(y_test, y_pred)\n\n# Compute accuracy\naccuracy = accuracy_score(y_test, y_pred)\n\n# Print results\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\nprint(\"\\nClassification Report:\")\nprint(cls_report)\nprint(\"\\nAccuracy:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-03-27T13:10:46.069068Z","iopub.execute_input":"2024-03-27T13:10:46.069443Z","iopub.status.idle":"2024-03-27T13:10:46.091028Z","shell.execute_reply.started":"2024-03-27T13:10:46.069415Z","shell.execute_reply":"2024-03-27T13:10:46.089922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Classifier names\nclassifiers = ['Logistic Regression', 'Random Forest', 'SVM', 'KNN', 'Naive Bayes', 'LSTM', 'Voting Classifier', 'Bert Based Uncased']\n\n# Accuracy scores\naccuracy_scores = [0.89187, 0.895501, 0.899133, 0.785758, 0.849102, 0.891063, 0.892879, 0.904579]\n\n# Sort classifiers and accuracy scores based on accuracy\nsorted_indices = sorted(range(len(accuracy_scores)), key=lambda k: accuracy_scores[k])\nclassifiers_sorted = [classifiers[i] for i in sorted_indices]\naccuracy_scores_sorted = [accuracy_scores[i] for i in sorted_indices]\n\n# Create column graph\nplt.figure(figsize=(10, 6))\nplt.barh(classifiers_sorted, accuracy_scores_sorted, color='skyblue')\nplt.xlabel('Accuracy')\nplt.title('Accuracy of Different Classifiers (Increasing Order)')\nplt.xlim(0.7, 1.0)  # Set x-axis limit\nplt.gca().invert_yaxis()  # Invert y-axis to show the highest accuracy on top\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-26T15:02:55.151571Z","iopub.execute_input":"2024-03-26T15:02:55.15239Z","iopub.status.idle":"2024-03-26T15:02:55.490718Z","shell.execute_reply.started":"2024-03-26T15:02:55.152358Z","shell.execute_reply":"2024-03-26T15:02:55.48954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Classifier names\nclassifiers = ['Logistic Regression', 'Random Forest', 'SVM', 'KNN', 'Naive Bayes', 'LSTM', 'Voting Classifier', 'Bert Based Uncased']\n\n# Accuracy scores\naccuracy_scores = [0.89187, 0.895501, 0.899133, 0.785758, 0.849102, 0.891063, 0.892879, 0.904579]\n\n# Sort classifiers and accuracy scores based on accuracy\nsorted_indices = sorted(range(len(accuracy_scores)), key=lambda k: accuracy_scores[k])\nclassifiers_sorted = [classifiers[i] for i in sorted_indices]\naccuracy_scores_sorted = [accuracy_scores[i] for i in sorted_indices]\n\n# Create column graph\nplt.figure(figsize=(10, 6))\nplt.barh(classifiers_sorted, accuracy_scores_sorted, color='skyblue')\nplt.xlabel('Accuracy')\nplt.title('Accuracy of Different Classifiers (Increasing Order)')\nplt.xlim(0.7, 1.0)  # Set x-axis limit\nplt.gca().invert_yaxis()  # Invert y-axis to show the highest accuracy on top\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-26T16:02:52.316788Z","iopub.execute_input":"2024-03-26T16:02:52.3177Z","iopub.status.idle":"2024-03-26T16:02:52.540138Z","shell.execute_reply.started":"2024-03-26T16:02:52.317662Z","shell.execute_reply":"2024-03-26T16:02:52.539251Z"},"trusted":true},"execution_count":null,"outputs":[]}]}